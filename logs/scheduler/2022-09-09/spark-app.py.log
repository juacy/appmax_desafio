[2022-09-09T15:31:23.050+0000] {processor.py:153} INFO - Started process (PID=1685) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:31:23.050+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:31:23.051+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:31:23.051+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:31:39.828+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T15:31:39.925+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T15:31:48.168+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:31:48.160+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 18, in <module>
    df = sqlContext.read.csv('file:///opt/airflow/dags/spark_jobs/ips.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/readwriter.py", line 535, in csv
    return self._df(self._jreader.csv(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1322, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/utils.py", line 196, in deco
    raise converted from None
pyspark.sql.utils.AnalysisException: Path does not exist: file:/opt/airflow/dags/spark_jobs/ips.csv
[2022-09-09T15:31:48.172+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:31:48.949+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 25.901 seconds
[2022-09-09T15:32:19.209+0000] {processor.py:153} INFO - Started process (PID=1898) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:32:19.210+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:32:19.210+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:32:19.210+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:32:41.435+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T15:32:41.538+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T15:32:42.281+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:32:42.274+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 18, in <module>
    #df = sqlContext.read.csv('file:///opt/airflow/dags/spark_jobs/ips.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/readwriter.py", line 535, in csv
    return self._df(self._jreader.csv(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1322, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/utils.py", line 196, in deco
    raise converted from None
pyspark.sql.utils.AnalysisException: Path does not exist: file:/opt/airflow/dags/spark_jobs/ips.csv
[2022-09-09T15:32:42.285+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:32:42.447+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 23.240 seconds
[2022-09-09T15:33:12.672+0000] {processor.py:153} INFO - Started process (PID=2101) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:33:12.680+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:33:12.681+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:33:12.680+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:33:17.233+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T15:33:20.650+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T15:33:20.651+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T15:33:20.651+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T15:33:20.651+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T15:33:20.651+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T15:33:20.651+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:33:20.651+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:33:20.651+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:33:20.651+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T15:33:20.651+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T15:33:20.651+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T15:33:20.651+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:33:20.651+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:33:20.652+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:33:20.652+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T15:33:20.652+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:33:20.652+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T15:33:20.652+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T15:33:20.653+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:33:20.652+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T15:33:20.654+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:33:20.780+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 8.111 seconds
[2022-09-09T15:33:50.953+0000] {processor.py:153} INFO - Started process (PID=2290) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:33:51.031+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:33:51.032+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:33:51.032+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:34:17.916+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T15:34:21.034+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:34:21.033+0000] {timeout.py:67} ERROR - Process timed out, PID: 2290
[2022-09-09T15:34:21.035+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:34:21.034+0000] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark-app.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#reducing-dag-complexity, PID: 2290
[2022-09-09T15:34:21.035+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:34:21.035+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-09-09T15:34:21.036+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:34:21.035+0000] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark-app.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#reducing-dag-complexity, PID: 2290

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-09-09T15:34:21.036+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:34:21.036+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-09-09T15:34:21.037+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:34:21.036+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 936, in _create_dataframe
    rdd, struct = self._createFromLocal(map(prepare, data), schema)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 631, in _createFromLocal
    struct = self._inferSchemaFromList(data, names=schema)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 515, in _inferSchemaFromList
    infer_dict_as_struct = self._jconf.inferDictAsStruct()
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 342, in _jconf
    return self._jsparkSession.sessionState().conf()
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1322, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/utils.py", line 190, in deco
    return f(*a, **kw)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling o27.sessionState
[2022-09-09T15:34:21.038+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:34:49.549+0000] {processor.py:153} INFO - Started process (PID=2442) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:34:49.600+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:34:49.600+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:34:49.600+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:34:52.804+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T15:34:54.057+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T15:34:54.057+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T15:34:54.057+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T15:34:54.057+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T15:34:54.058+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T15:34:54.058+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:34:54.058+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:34:54.058+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:34:54.058+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T15:34:54.058+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T15:34:54.058+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T15:34:54.058+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:34:54.058+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:34:54.059+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:34:54.059+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T15:34:54.059+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:34:54.059+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T15:34:54.059+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T15:34:54.064+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:34:54.059+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T15:34:54.066+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:34:54.502+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.956 seconds
[2022-09-09T15:35:27.939+0000] {processor.py:153} INFO - Started process (PID=2635) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:35:27.970+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:35:27.971+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:35:27.971+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:35:38.937+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T15:35:40.528+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T15:35:40.529+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T15:35:40.529+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T15:35:40.529+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T15:35:40.529+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T15:35:40.529+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:35:40.529+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:35:40.529+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:35:40.529+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T15:35:40.530+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T15:35:40.530+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T15:35:40.530+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:35:40.530+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:35:40.530+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:35:40.530+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T15:35:40.530+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:35:40.530+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T15:35:40.530+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T15:35:40.532+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:35:40.531+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T15:35:40.533+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:35:40.764+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 12.828 seconds
[2022-09-09T15:36:10.982+0000] {processor.py:153} INFO - Started process (PID=2827) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:36:10.991+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:36:10.992+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:36:10.991+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:36:13.900+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T15:36:15.245+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T15:36:15.246+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T15:36:15.246+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T15:36:15.246+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T15:36:15.246+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T15:36:15.246+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:36:15.246+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:36:15.246+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:36:15.247+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T15:36:15.247+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T15:36:15.247+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T15:36:15.247+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:36:15.247+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:36:15.247+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:36:15.247+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T15:36:15.247+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:36:15.247+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T15:36:15.247+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T15:36:15.250+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:36:15.248+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T15:36:15.250+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:36:15.339+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.359 seconds
[2022-09-09T15:36:45.768+0000] {processor.py:153} INFO - Started process (PID=3007) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:36:45.777+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:36:45.777+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:36:45.777+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:36:48.608+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T15:36:49.794+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T15:36:49.794+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T15:36:49.794+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T15:36:49.795+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T15:36:49.795+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T15:36:49.795+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:36:49.795+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:36:49.795+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:36:49.795+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T15:36:49.795+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T15:36:49.795+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T15:36:49.795+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:36:49.796+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:36:49.796+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:36:49.796+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T15:36:49.796+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:36:49.796+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T15:36:49.796+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T15:36:49.799+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:36:49.796+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T15:36:49.799+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:36:49.915+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.150 seconds
[2022-09-09T15:37:20.378+0000] {processor.py:153} INFO - Started process (PID=3185) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:37:20.378+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:37:20.379+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:37:20.379+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:37:23.309+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T15:37:24.528+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T15:37:24.528+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T15:37:24.528+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T15:37:24.528+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T15:37:24.528+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T15:37:24.528+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:37:24.528+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:37:24.528+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:37:24.528+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T15:37:24.529+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T15:37:24.529+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T15:37:24.529+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:37:24.529+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:37:24.529+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:37:24.529+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T15:37:24.529+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:37:24.529+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T15:37:24.529+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T15:37:24.531+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:37:24.529+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T15:37:24.531+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:37:24.572+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.197 seconds
[2022-09-09T15:37:54.892+0000] {processor.py:153} INFO - Started process (PID=3366) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:37:54.893+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:37:54.893+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:37:54.893+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:37:57.708+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T15:37:58.865+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T15:37:58.866+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T15:37:58.866+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T15:37:58.866+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T15:37:58.866+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T15:37:58.866+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:37:58.867+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:37:58.867+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:37:58.867+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T15:37:58.867+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T15:37:58.867+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T15:37:58.867+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:37:58.867+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:37:58.867+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:37:58.867+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T15:37:58.867+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:37:58.868+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T15:37:58.868+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T15:37:58.870+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:37:58.868+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T15:37:58.871+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:37:58.940+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.050 seconds
[2022-09-09T15:38:29.376+0000] {processor.py:153} INFO - Started process (PID=3555) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:38:29.377+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:38:29.377+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:38:29.377+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:38:32.266+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T15:38:33.499+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T15:38:33.499+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T15:38:33.499+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T15:38:33.499+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T15:38:33.499+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T15:38:33.499+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:38:33.500+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:38:33.500+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:38:33.500+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T15:38:33.500+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T15:38:33.500+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T15:38:33.500+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:38:33.500+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:38:33.500+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:38:33.500+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T15:38:33.500+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:38:33.501+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T15:38:33.501+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T15:38:33.503+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:38:33.501+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T15:38:33.504+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:38:33.562+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.188 seconds
[2022-09-09T15:39:03.936+0000] {processor.py:153} INFO - Started process (PID=3746) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:39:03.937+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:39:03.937+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:39:03.937+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:39:06.831+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T15:39:08.059+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T15:39:08.059+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T15:39:08.059+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T15:39:08.059+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T15:39:08.060+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T15:39:08.060+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:39:08.060+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:39:08.060+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:39:08.060+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T15:39:08.060+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T15:39:08.060+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T15:39:08.060+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:39:08.060+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:39:08.060+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:39:08.060+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T15:39:08.060+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:39:08.060+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T15:39:08.061+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T15:39:08.063+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:39:08.061+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T15:39:08.063+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:39:08.115+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.181 seconds
[2022-09-09T15:39:38.351+0000] {processor.py:153} INFO - Started process (PID=3937) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:39:38.351+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:39:38.352+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:39:38.351+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:39:41.185+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T15:39:42.366+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T15:39:42.366+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T15:39:42.366+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T15:39:42.366+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T15:39:42.366+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T15:39:42.366+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:39:42.366+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:39:42.366+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:39:42.367+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T15:39:42.367+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T15:39:42.367+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T15:39:42.367+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:39:42.367+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:39:42.367+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:39:42.367+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T15:39:42.367+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:39:42.367+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T15:39:42.367+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T15:39:42.369+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:39:42.367+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T15:39:42.370+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:39:42.435+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.087 seconds
[2022-09-09T15:40:13.272+0000] {processor.py:153} INFO - Started process (PID=4114) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:40:13.272+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:40:13.273+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:40:13.273+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:40:16.082+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T15:40:17.216+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T15:40:17.216+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T15:40:17.217+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T15:40:17.217+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T15:40:17.217+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T15:40:17.217+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:40:17.217+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:40:17.217+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:40:17.217+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T15:40:17.217+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T15:40:17.217+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T15:40:17.217+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:40:17.217+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:40:17.217+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:40:17.217+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T15:40:17.217+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:40:17.217+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T15:40:17.218+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T15:40:17.219+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:40:17.218+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T15:40:17.220+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:40:17.272+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.003 seconds
[2022-09-09T15:40:33.209+0000] {processor.py:153} INFO - Started process (PID=4270) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:40:33.210+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:40:33.210+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:40:33.210+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:40:33.211+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:40:33.211+0000] {dagbag.py:301} INFO - File /opt/airflow/dags/spark-app.py assumed to contain no DAGs. Skipping.
[2022-09-09T15:40:33.211+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:40:33.303+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 0.097 seconds
[2022-09-09T15:41:03.644+0000] {processor.py:153} INFO - Started process (PID=4327) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:41:03.692+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:41:03.693+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:41:03.693+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:41:03.693+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:41:03.693+0000] {dagbag.py:301} INFO - File /opt/airflow/dags/spark-app.py assumed to contain no DAGs. Skipping.
[2022-09-09T15:41:03.693+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:41:03.706+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 0.065 seconds
[2022-09-09T15:46:23.780+0000] {processor.py:153} INFO - Started process (PID=4907) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:46:23.792+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:46:23.792+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:46:23.792+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:46:54.596+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:46:54.595+0000] {timeout.py:67} ERROR - Process timed out, PID: 4907
[2022-09-09T15:46:56.461+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:46:54.596+0000] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark-app.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#reducing-dag-complexity, PID: 4907
[2022-09-09T15:46:56.462+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:46:56.461+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-09-09T15:46:56.463+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:46:56.462+0000] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark-app.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#reducing-dag-complexity, PID: 4907

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-09-09T15:46:56.463+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:46:56.463+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-09-09T15:46:56.464+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:46:56.463+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 5, in <module>
    sc = SparkContext("local", "First App")
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 208, in __init__
    udf_profiler_cls,
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 282, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 402, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1586, in __call__
    answer, self._gateway_client, None, self._fqn)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-09-09T15:46:56.464+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:46:56.657+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 32.880 seconds
[2022-09-09T15:47:26.927+0000] {processor.py:153} INFO - Started process (PID=5036) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:47:26.927+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:47:26.928+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:47:26.928+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:47:47.001+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T15:47:47.898+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T15:47:56.929+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:47:56.929+0000] {timeout.py:67} ERROR - Process timed out, PID: 5036
[2022-09-09T15:47:56.930+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:47:56.929+0000] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark-app.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#reducing-dag-complexity, PID: 5036
[2022-09-09T15:47:56.930+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:47:56.930+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-09-09T15:47:56.931+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:47:56.930+0000] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark-app.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#reducing-dag-complexity, PID: 5036

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-09-09T15:47:56.931+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:47:56.931+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-09-09T15:47:56.932+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:47:56.931+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 18, in <module>
    df = sqlContext.read.csv('file:///opt/airflow/dags/spark_jobs/dados/bronze/ips.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 649, in read
    return DataFrameReader(self.sparkSession)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/readwriter.py", line 66, in __init__
    self._jreader = spark._jsparkSession.read()
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1322, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/utils.py", line 190, in deco
    return f(*a, **kw)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling o27.read
[2022-09-09T15:47:56.933+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:48:31.882+0000] {processor.py:153} INFO - Started process (PID=5185) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:48:31.930+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:48:31.930+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:48:31.930+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:48:34.988+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T15:48:35.098+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T15:48:35.877+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:48:35.868+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 18, in <module>
    df = sqlContext.read.csv('file:///opt/airflow/dags/spark_jobs/dados/bronze/ips.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/readwriter.py", line 535, in csv
    return self._df(self._jreader.csv(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1322, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/utils.py", line 196, in deco
    raise converted from None
pyspark.sql.utils.AnalysisException: Path does not exist: file:/opt/airflow/dags/spark_jobs/dados/bronze/ips.csv
[2022-09-09T15:48:35.881+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:48:36.145+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.266 seconds
[2022-09-09T15:48:49.186+0000] {processor.py:153} INFO - Started process (PID=5316) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:48:49.187+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:48:49.187+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:48:49.187+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:49:05.044+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T15:49:05.140+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T15:49:05.817+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:49:05.809+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 18, in <module>
    df = sqlContext.read.csv('file:///opt/airflow/dags/spark_jobs/ips.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/readwriter.py", line 535, in csv
    return self._df(self._jreader.csv(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1322, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/utils.py", line 196, in deco
    raise converted from None
pyspark.sql.utils.AnalysisException: Path does not exist: file:/opt/airflow/dags/spark_jobs/ips.csv
[2022-09-09T15:49:05.821+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:49:06.025+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 16.842 seconds
[2022-09-09T15:52:47.554+0000] {processor.py:153} INFO - Started process (PID=5471) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:52:48.056+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:52:48.056+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:52:48.056+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:52:52.211+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T15:52:52.316+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T15:52:53.178+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:52:53.169+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 18, in <module>
    df = sqlContext.read.csv('file:///opt/airflow/dags/spark_jobs/ips.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/readwriter.py", line 535, in csv
    return self._df(self._jreader.csv(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1322, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/utils.py", line 196, in deco
    raise converted from None
pyspark.sql.utils.AnalysisException: Path does not exist: file:/opt/airflow/dags/spark_jobs/ips.csv
[2022-09-09T15:52:53.183+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:52:53.246+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 5.696 seconds
[2022-09-09T15:53:36.213+0000] {processor.py:153} INFO - Started process (PID=5644) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:53:36.271+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:53:36.272+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:53:36.272+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:53:39.367+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T15:53:39.465+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T15:53:40.166+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:53:40.158+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 18, in <module>
    df = sqlContext.read.csv('file:///opt/airflow/dags/spark_jobs/ips.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/readwriter.py", line 535, in csv
    return self._df(self._jreader.csv(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1322, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/utils.py", line 196, in deco
    raise converted from None
pyspark.sql.utils.AnalysisException: Path does not exist: file:/opt/airflow/dags/spark_jobs/ips.csv
[2022-09-09T15:53:40.170+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:53:40.372+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.161 seconds
[2022-09-09T15:54:10.404+0000] {processor.py:153} INFO - Started process (PID=5835) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:54:10.417+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:54:10.418+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:54:10.418+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:54:13.291+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T15:54:13.387+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T15:54:14.074+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:54:14.067+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 18, in <module>
    df = sqlContext.read.csv('file:///opt/airflow/dags/spark_jobs/ips.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/readwriter.py", line 535, in csv
    return self._df(self._jreader.csv(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1322, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/utils.py", line 196, in deco
    raise converted from None
pyspark.sql.utils.AnalysisException: Path does not exist: file:/opt/airflow/dags/spark_jobs/ips.csv
[2022-09-09T15:54:14.078+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:54:14.152+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 3.751 seconds
[2022-09-09T15:54:44.419+0000] {processor.py:153} INFO - Started process (PID=6026) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:54:44.420+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:54:44.421+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:54:44.421+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:54:47.533+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T15:54:47.630+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T15:54:48.372+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:54:48.365+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 18, in <module>
    df = sqlContext.read.csv('file:///opt/airflow/dags/spark_jobs/ips.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/readwriter.py", line 535, in csv
    return self._df(self._jreader.csv(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1322, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/utils.py", line 196, in deco
    raise converted from None
pyspark.sql.utils.AnalysisException: Path does not exist: file:/opt/airflow/dags/spark_jobs/ips.csv
[2022-09-09T15:54:48.376+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:54:48.435+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.018 seconds
[2022-09-09T15:55:18.572+0000] {processor.py:153} INFO - Started process (PID=6201) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:55:18.582+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:55:18.582+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:55:18.582+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:55:21.757+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T15:55:21.860+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T15:55:22.568+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:55:22.560+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 18, in <module>
    df = sqlContext.read.csv('file:///opt/airflow/dags/spark_jobs/ips.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/readwriter.py", line 535, in csv
    return self._df(self._jreader.csv(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1322, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/utils.py", line 196, in deco
    raise converted from None
pyspark.sql.utils.AnalysisException: Path does not exist: file:/opt/airflow/dags/spark_jobs/ips.csv
[2022-09-09T15:55:22.572+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:55:22.625+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.057 seconds
[2022-09-09T15:55:52.736+0000] {processor.py:153} INFO - Started process (PID=6379) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:55:52.756+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:55:52.757+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:55:52.757+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:55:55.802+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T15:55:55.908+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T15:55:56.720+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:55:56.712+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 18, in <module>
    df = sqlContext.read.csv('file:///opt/airflow/dags/spark_jobs/ips.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/readwriter.py", line 535, in csv
    return self._df(self._jreader.csv(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1322, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/utils.py", line 196, in deco
    raise converted from None
pyspark.sql.utils.AnalysisException: Path does not exist: file:/opt/airflow/dags/spark_jobs/ips.csv
[2022-09-09T15:55:56.724+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:55:56.825+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.091 seconds
[2022-09-09T15:56:06.773+0000] {processor.py:153} INFO - Started process (PID=6513) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:56:06.774+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:56:06.775+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:56:06.774+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:56:09.893+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T15:56:11.079+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T15:56:11.079+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T15:56:11.080+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T15:56:11.080+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T15:56:11.080+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T15:56:11.080+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:56:11.080+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:56:11.080+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:56:11.080+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T15:56:11.080+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T15:56:11.080+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T15:56:11.080+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:56:11.080+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:56:11.080+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:56:11.081+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T15:56:11.081+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:56:11.081+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T15:56:11.081+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T15:56:11.083+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:56:11.081+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T15:56:11.083+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:56:11.149+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.378 seconds
[2022-09-09T15:57:09.490+0000] {processor.py:153} INFO - Started process (PID=6673) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:57:10.387+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:57:10.388+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:57:10.388+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:57:13.356+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T15:57:14.535+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T15:57:14.535+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T15:57:14.535+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T15:57:14.535+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T15:57:14.535+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T15:57:14.535+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:57:14.535+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:57:14.535+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:57:14.536+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T15:57:14.536+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T15:57:14.536+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T15:57:14.536+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:57:14.536+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:57:14.536+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:57:14.536+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T15:57:14.536+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:57:14.536+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T15:57:14.536+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T15:57:14.538+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:57:14.536+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T15:57:14.538+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:57:14.580+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 5.094 seconds
[2022-09-09T15:57:45.258+0000] {processor.py:153} INFO - Started process (PID=6877) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:57:45.274+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:57:45.274+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:57:45.274+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:57:48.004+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T15:57:49.136+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T15:57:49.136+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T15:57:49.137+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T15:57:49.137+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T15:57:49.137+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T15:57:49.137+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:57:49.137+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:57:49.137+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:57:49.137+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T15:57:49.137+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T15:57:49.137+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T15:57:49.138+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:57:49.138+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:57:49.138+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:57:49.138+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T15:57:49.138+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:57:49.138+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T15:57:49.138+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T15:57:49.141+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:57:49.138+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T15:57:49.141+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:57:49.180+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 3.925 seconds
[2022-09-09T15:58:19.987+0000] {processor.py:153} INFO - Started process (PID=7061) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:58:19.988+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:58:19.988+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:58:19.988+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:58:22.873+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T15:58:24.042+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T15:58:24.042+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T15:58:24.042+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T15:58:24.043+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T15:58:24.043+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T15:58:24.043+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:58:24.043+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:58:24.043+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:58:24.043+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T15:58:24.043+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T15:58:24.043+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T15:58:24.043+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:58:24.044+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:58:24.044+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:58:24.044+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T15:58:24.044+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:58:24.044+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T15:58:24.044+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T15:58:24.046+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:58:24.044+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T15:58:24.047+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:58:24.129+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.144 seconds
[2022-09-09T15:58:30.154+0000] {processor.py:153} INFO - Started process (PID=7183) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:58:30.155+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:58:30.156+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:58:30.156+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:58:33.458+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T15:58:34.589+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T15:58:34.589+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T15:58:34.589+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T15:58:34.590+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T15:58:34.590+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T15:58:34.590+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:58:34.590+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:58:34.590+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:58:34.590+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T15:58:34.590+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T15:58:34.590+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T15:58:34.590+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:58:34.590+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:58:34.590+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:58:34.590+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T15:58:34.590+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:58:34.590+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T15:58:34.591+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T15:58:34.592+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:58:34.591+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T15:58:34.593+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:58:34.637+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.485 seconds
[2022-09-09T15:59:05.188+0000] {processor.py:153} INFO - Started process (PID=7361) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:59:05.206+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:59:05.206+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:59:05.206+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:59:08.164+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T15:59:09.420+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T15:59:09.420+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T15:59:09.420+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T15:59:09.420+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T15:59:09.420+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T15:59:09.420+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:59:09.420+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:59:09.420+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:59:09.420+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T15:59:09.421+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T15:59:09.421+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T15:59:09.421+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:59:09.421+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:59:09.421+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:59:09.421+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T15:59:09.421+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:59:09.421+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T15:59:09.421+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T15:59:09.423+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:59:09.421+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T15:59:09.423+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:59:09.477+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.291 seconds
[2022-09-09T15:59:40.262+0000] {processor.py:153} INFO - Started process (PID=7539) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T15:59:40.272+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T15:59:40.272+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:59:40.272+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T15:59:43.018+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T15:59:44.288+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T15:59:44.288+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T15:59:44.288+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T15:59:44.288+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T15:59:44.288+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T15:59:44.288+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:59:44.288+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:59:44.288+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:59:44.288+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T15:59:44.289+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T15:59:44.289+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T15:59:44.289+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:59:44.289+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T15:59:44.289+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:59:44.289+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T15:59:44.289+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T15:59:44.289+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T15:59:44.289+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T15:59:44.291+0000] {logging_mixin.py:115} INFO - [2022-09-09T15:59:44.289+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T15:59:44.292+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T15:59:44.355+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.096 seconds
[2022-09-09T16:00:14.669+0000] {processor.py:153} INFO - Started process (PID=7724) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:00:14.712+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:00:14.713+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:00:14.713+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:00:17.634+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:00:18.819+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T16:00:18.820+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T16:00:18.820+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T16:00:18.820+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T16:00:18.820+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T16:00:18.820+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:00:18.820+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:00:18.820+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:00:18.820+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T16:00:18.820+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T16:00:18.820+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T16:00:18.820+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:00:18.820+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:00:18.820+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:00:18.820+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T16:00:18.821+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:00:18.821+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T16:00:18.821+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T16:00:18.823+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:00:18.821+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T16:00:18.823+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:00:18.862+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.197 seconds
[2022-09-09T16:00:49.762+0000] {processor.py:153} INFO - Started process (PID=7919) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:00:49.763+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:00:49.764+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:00:49.764+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:00:52.710+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:00:53.870+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T16:00:53.870+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T16:00:53.870+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T16:00:53.870+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T16:00:53.870+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T16:00:53.870+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:00:53.870+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:00:53.870+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:00:53.870+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T16:00:53.871+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T16:00:53.871+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T16:00:53.871+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:00:53.871+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:00:53.871+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:00:53.871+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T16:00:53.871+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:00:53.871+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T16:00:53.871+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T16:00:53.873+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:00:53.871+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T16:00:53.873+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:00:53.916+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.156 seconds
[2022-09-09T16:01:23.981+0000] {processor.py:153} INFO - Started process (PID=8108) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:01:23.982+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:01:23.983+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:01:23.983+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:01:28.593+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:01:29.777+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T16:01:29.777+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T16:01:29.777+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T16:01:29.778+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T16:01:29.778+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T16:01:29.778+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:01:29.778+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:01:29.778+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:01:29.778+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T16:01:29.778+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T16:01:29.778+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T16:01:29.778+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:01:29.778+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:01:29.778+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:01:29.778+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T16:01:29.778+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:01:29.778+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T16:01:29.779+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T16:01:29.780+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:01:29.779+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T16:01:29.781+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:01:29.856+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 5.878 seconds
[2022-09-09T16:02:00.107+0000] {processor.py:153} INFO - Started process (PID=8287) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:02:00.158+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:02:00.159+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:02:00.159+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:02:02.928+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:02:04.121+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T16:02:04.121+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T16:02:04.121+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T16:02:04.121+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T16:02:04.121+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T16:02:04.121+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:02:04.121+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:02:04.121+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:02:04.122+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T16:02:04.122+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T16:02:04.122+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T16:02:04.122+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:02:04.122+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:02:04.122+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:02:04.122+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T16:02:04.122+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:02:04.122+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T16:02:04.122+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T16:02:04.124+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:02:04.122+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T16:02:04.124+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:02:04.331+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.227 seconds
[2022-09-09T16:02:34.423+0000] {processor.py:153} INFO - Started process (PID=8464) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:02:34.440+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:02:34.441+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:02:34.441+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:02:37.164+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:02:38.305+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T16:02:38.305+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T16:02:38.305+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T16:02:38.305+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T16:02:38.305+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T16:02:38.305+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:02:38.306+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:02:38.306+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:02:38.306+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T16:02:38.306+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T16:02:38.306+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T16:02:38.306+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:02:38.306+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:02:38.306+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:02:38.306+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T16:02:38.306+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:02:38.306+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T16:02:38.306+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T16:02:38.309+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:02:38.307+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T16:02:38.309+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:02:38.391+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 3.970 seconds
[2022-09-09T16:02:58.715+0000] {processor.py:153} INFO - Started process (PID=8633) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:02:58.715+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:02:58.716+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:02:58.716+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:03:01.794+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:03:12.432+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T16:03:12.432+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T16:03:12.432+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T16:03:12.432+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T16:03:12.432+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T16:03:12.432+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:03:12.432+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:03:12.432+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:03:12.433+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T16:03:12.433+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T16:03:12.433+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T16:03:12.433+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:03:12.433+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:03:12.433+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:03:12.433+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T16:03:12.433+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:03:12.433+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T16:03:12.434+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T16:03:12.436+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:03:12.434+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T16:03:12.437+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:03:12.511+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 13.799 seconds
[2022-09-09T16:03:56.472+0000] {processor.py:153} INFO - Started process (PID=8788) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:03:56.574+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:03:56.574+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:03:56.574+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:03:59.427+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:04:00.588+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T16:04:00.588+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T16:04:00.588+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T16:04:00.588+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T16:04:00.588+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T16:04:00.589+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:04:00.589+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:04:00.589+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:04:00.589+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T16:04:00.589+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T16:04:00.589+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T16:04:00.589+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:04:00.589+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:04:00.589+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:04:00.590+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T16:04:00.590+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:04:00.590+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T16:04:00.590+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T16:04:00.593+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:04:00.590+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T16:04:00.593+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:04:01.077+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.608 seconds
[2022-09-09T16:04:31.921+0000] {processor.py:153} INFO - Started process (PID=8977) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:04:31.973+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:04:31.974+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:04:31.974+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:04:34.977+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:04:36.198+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T16:04:36.199+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T16:04:36.199+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T16:04:36.199+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T16:04:36.199+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T16:04:36.199+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:04:36.199+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:04:36.199+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:04:36.199+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T16:04:36.199+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T16:04:36.199+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T16:04:36.199+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:04:36.199+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:04:36.199+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:04:36.200+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T16:04:36.200+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:04:36.200+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T16:04:36.200+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T16:04:36.202+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:04:36.200+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T16:04:36.202+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:04:36.259+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.341 seconds
[2022-09-09T16:05:07.041+0000] {processor.py:153} INFO - Started process (PID=9172) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:05:07.064+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:05:07.064+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:05:07.064+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:05:20.884+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:05:21.966+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T16:05:21.967+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T16:05:21.967+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T16:05:21.967+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T16:05:21.967+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T16:05:21.967+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:05:21.967+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:05:21.967+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:05:21.967+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T16:05:21.967+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T16:05:21.967+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T16:05:21.967+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:05:21.967+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:05:21.967+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:05:21.967+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T16:05:21.968+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:05:21.968+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T16:05:21.968+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T16:05:21.970+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:05:21.968+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T16:05:21.970+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:05:22.033+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 14.995 seconds
[2022-09-09T16:05:52.369+0000] {processor.py:153} INFO - Started process (PID=9353) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:05:52.396+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:05:52.397+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:05:52.397+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:05:55.198+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:06:09.950+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T16:06:09.950+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T16:06:09.950+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T16:06:09.950+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T16:06:09.950+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T16:06:09.950+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:06:09.950+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:06:09.950+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:06:09.950+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T16:06:09.950+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T16:06:09.951+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T16:06:09.951+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:06:09.951+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:06:09.951+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:06:09.951+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T16:06:09.951+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:06:09.951+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T16:06:09.951+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T16:06:09.953+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:06:09.951+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T16:06:09.953+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:06:10.015+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 17.650 seconds
[2022-09-09T16:09:13.194+0000] {processor.py:153} INFO - Started process (PID=43) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:09:13.222+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:09:13.222+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:09:13.222+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:09:16.776+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:09:18.789+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T16:09:18.789+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T16:09:18.789+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T16:09:18.789+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T16:09:18.790+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T16:09:18.790+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:09:18.790+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:09:18.790+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:09:18.790+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T16:09:18.790+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T16:09:18.790+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T16:09:18.790+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:09:18.790+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:09:18.791+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:09:18.791+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T16:09:18.791+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:09:18.791+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T16:09:18.791+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T16:09:18.793+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:09:18.791+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T16:09:18.794+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:09:18.944+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 5.754 seconds
[2022-09-09T16:09:48.983+0000] {processor.py:153} INFO - Started process (PID=263) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:09:49.002+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:09:49.002+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:09:49.002+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:09:51.972+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:09:53.193+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T16:09:53.194+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T16:09:53.194+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T16:09:53.194+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T16:09:53.194+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T16:09:53.194+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:09:53.194+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:09:53.194+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:09:53.194+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T16:09:53.194+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T16:09:53.194+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T16:09:53.194+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:09:53.194+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:09:53.194+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:09:53.195+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T16:09:53.195+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:09:53.195+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T16:09:53.195+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T16:09:53.197+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:09:53.195+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T16:09:53.198+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:09:53.367+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.387 seconds
[2022-09-09T16:10:23.762+0000] {processor.py:153} INFO - Started process (PID=437) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:10:23.794+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:10:23.794+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:10:23.794+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:10:26.671+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:10:27.841+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T16:10:27.841+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T16:10:27.841+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T16:10:27.841+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T16:10:27.841+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T16:10:27.841+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:10:27.841+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:10:27.842+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:10:27.842+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T16:10:27.842+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T16:10:27.842+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T16:10:27.842+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:10:27.842+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:10:27.842+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:10:27.842+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T16:10:27.842+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:10:27.842+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T16:10:27.843+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T16:10:27.845+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:10:27.843+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T16:10:27.846+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:10:27.899+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.139 seconds
[2022-09-09T16:10:58.833+0000] {processor.py:153} INFO - Started process (PID=625) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:10:58.863+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:10:58.864+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:10:58.864+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:11:02.047+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:11:42.745+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:11:42.744+0000] {timeout.py:67} ERROR - Process timed out, PID: 625
[2022-09-09T16:11:42.746+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:11:42.745+0000] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark-app.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#reducing-dag-complexity, PID: 625
[2022-09-09T16:11:42.746+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:11:42.746+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-09-09T16:11:42.747+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:11:42.746+0000] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark-app.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#reducing-dag-complexity, PID: 625

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-09-09T16:11:42.747+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:11:42.747+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-09-09T16:11:42.749+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:11:42.748+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 936, in _create_dataframe
    rdd, struct = self._createFromLocal(map(prepare, data), schema)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 648, in _createFromLocal
    return self._sc.parallelize(internal_data), struct
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 674, in parallelize
    jrdd = self._serialize_to_jvm(c, serializer, reader_func, createRDDServer)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 720, in _serialize_to_jvm
    return reader_func(tempFile.name)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 668, in reader_func
    return self._jvm.PythonRDD.readRDDFromFile(self._jsc, temp_filename, numSlices)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1322, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/utils.py", line 190, in deco
    return f(*a, **kw)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.readRDDFromFile
[2022-09-09T16:11:42.749+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:11:43.995+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 45.165 seconds
[2022-09-09T16:12:21.366+0000] {processor.py:153} INFO - Started process (PID=778) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:12:24.090+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:12:24.090+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:12:24.090+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:12:56.755+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:12:56.754+0000] {timeout.py:67} ERROR - Process timed out, PID: 778
[2022-09-09T16:13:31.883+0000] {processor.py:153} INFO - Started process (PID=835) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:13:31.884+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:13:31.884+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:13:31.884+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:13:35.104+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:13:36.334+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T16:13:36.334+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T16:13:36.334+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T16:13:36.334+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T16:13:36.334+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T16:13:36.334+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:13:36.334+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:13:36.334+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:13:36.334+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T16:13:36.335+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T16:13:36.335+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T16:13:36.335+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:13:36.335+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:13:36.335+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:13:36.335+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T16:13:36.335+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:13:36.335+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T16:13:36.335+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T16:13:36.338+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:13:36.335+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T16:13:36.338+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:13:36.588+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.708 seconds
[2022-09-09T16:14:06.868+0000] {processor.py:153} INFO - Started process (PID=1016) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:14:07.003+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:14:07.004+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:14:07.004+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:14:10.532+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:14:11.793+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T16:14:11.793+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T16:14:11.793+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T16:14:11.793+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T16:14:11.793+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T16:14:11.794+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:14:11.794+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:14:11.794+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:14:11.794+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T16:14:11.794+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T16:14:11.794+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T16:14:11.794+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:14:11.794+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:14:11.794+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:14:11.794+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T16:14:11.794+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:14:11.794+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T16:14:11.794+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T16:14:11.796+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:14:11.795+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T16:14:11.797+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:14:12.068+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 5.203 seconds
[2022-09-09T16:14:42.358+0000] {processor.py:153} INFO - Started process (PID=1205) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:14:42.397+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:14:42.397+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:14:42.397+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:14:45.401+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:14:46.618+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T16:14:46.618+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T16:14:46.708+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T16:14:46.708+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T16:14:46.709+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T16:14:46.709+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:14:46.709+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:14:46.709+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:14:46.709+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T16:14:46.709+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T16:14:46.709+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T16:14:46.709+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:14:46.709+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:14:46.709+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:14:46.709+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T16:14:46.709+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:14:46.709+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T16:14:46.709+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T16:14:46.712+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:14:46.710+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T16:14:46.712+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:14:47.309+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.954 seconds
[2022-09-09T16:15:17.547+0000] {processor.py:153} INFO - Started process (PID=1392) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:15:17.594+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:15:17.594+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:15:17.594+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:15:20.551+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:15:21.817+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T16:15:21.817+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T16:15:21.817+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T16:15:21.817+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T16:15:21.817+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T16:15:21.817+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:15:21.817+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:15:21.817+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:15:21.817+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T16:15:21.818+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T16:15:21.818+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T16:15:21.818+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:15:21.818+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:15:21.818+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:15:21.818+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T16:15:21.818+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:15:21.818+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T16:15:21.818+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T16:15:21.820+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:15:21.818+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T16:15:21.820+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:15:21.891+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.347 seconds
[2022-09-09T16:15:52.271+0000] {processor.py:153} INFO - Started process (PID=1572) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:15:52.303+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:15:52.304+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:15:52.304+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:15:55.008+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:15:56.210+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T16:15:56.211+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T16:15:56.307+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T16:15:56.307+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T16:15:56.307+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T16:15:56.307+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:15:56.307+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:15:56.308+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:15:56.308+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T16:15:56.308+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T16:15:56.308+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T16:15:56.308+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:15:56.308+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:15:56.308+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:15:56.308+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T16:15:56.308+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:15:56.308+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T16:15:56.308+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T16:15:56.310+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:15:56.308+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T16:15:56.310+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:15:56.663+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.395 seconds
[2022-09-09T16:16:27.066+0000] {processor.py:153} INFO - Started process (PID=1751) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:16:27.094+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:16:27.095+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:16:27.095+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:16:30.849+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:16:32.015+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T16:16:32.016+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T16:16:32.016+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T16:16:32.016+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T16:16:32.016+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T16:16:32.016+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:16:32.016+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:16:32.016+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:16:32.016+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T16:16:32.016+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T16:16:32.016+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T16:16:32.016+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:16:32.017+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:16:32.017+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:16:32.017+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T16:16:32.017+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:16:32.017+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T16:16:32.017+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T16:16:32.019+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:16:32.017+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T16:16:32.019+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:16:32.447+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 5.384 seconds
[2022-09-09T16:16:38.104+0000] {processor.py:153} INFO - Started process (PID=1884) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:16:38.105+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:16:38.105+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:16:38.105+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:16:41.236+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:17:43.279+0000] {processor.py:153} INFO - Started process (PID=1997) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:17:43.280+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:17:43.280+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:17:43.280+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:17:48.745+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:18:32.294+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:18:32.293+0000] {timeout.py:67} ERROR - Process timed out, PID: 1997
[2022-09-09T16:18:32.295+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:18:32.294+0000] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark-app.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#reducing-dag-complexity, PID: 1997
[2022-09-09T16:18:38.713+0000] {processor.py:153} INFO - Started process (PID=2162) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:18:38.756+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:18:38.757+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:18:38.757+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:18:47.957+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:18:49.283+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T16:18:49.283+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T16:18:49.283+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T16:18:49.284+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T16:18:49.284+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T16:18:49.284+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:18:49.284+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:18:49.284+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:18:49.284+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T16:18:49.284+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T16:18:49.284+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T16:18:49.284+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:18:49.284+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:18:49.285+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:18:49.285+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T16:18:49.285+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:18:49.285+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T16:18:49.285+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T16:18:49.288+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:18:49.285+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T16:18:49.288+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:18:49.727+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 11.017 seconds
[2022-09-09T16:19:20.428+0000] {processor.py:153} INFO - Started process (PID=2357) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:19:20.464+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:19:20.465+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:19:20.465+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:19:23.330+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:19:24.482+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T16:19:24.482+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T16:19:24.509+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T16:19:24.509+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T16:19:24.510+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T16:19:24.510+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:19:24.510+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:19:24.510+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:19:24.510+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T16:19:24.510+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T16:19:24.510+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T16:19:24.510+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:19:24.510+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:19:24.510+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:19:24.510+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T16:19:24.510+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:19:24.510+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T16:19:24.510+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T16:19:24.512+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:19:24.511+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T16:19:24.513+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:19:24.651+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.226 seconds
[2022-09-09T16:19:54.714+0000] {processor.py:153} INFO - Started process (PID=2533) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:19:54.763+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:19:54.764+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:19:54.764+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:19:57.531+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:19:58.681+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T16:19:58.681+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T16:19:58.681+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T16:19:58.682+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T16:19:58.682+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T16:19:58.682+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:19:58.682+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:19:58.682+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:19:58.682+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T16:19:58.682+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T16:19:58.682+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T16:19:58.682+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:19:58.682+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:19:58.682+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:19:58.682+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T16:19:58.682+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:19:58.682+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T16:19:58.683+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T16:19:58.684+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:19:58.683+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T16:19:58.685+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:19:58.792+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.080 seconds
[2022-09-09T16:20:29.074+0000] {processor.py:153} INFO - Started process (PID=2710) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:20:29.074+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:20:29.075+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:20:29.075+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:20:32.249+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:20:33.412+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T16:20:33.412+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T16:20:33.412+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T16:20:33.412+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T16:20:33.413+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T16:20:33.413+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:20:33.413+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:20:33.413+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:20:33.413+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T16:20:33.413+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T16:20:33.413+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T16:20:33.413+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:20:33.413+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:20:33.413+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:20:33.413+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T16:20:33.413+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:20:33.414+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T16:20:33.414+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T16:20:33.416+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:20:33.414+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T16:20:33.416+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:20:33.530+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.459 seconds
[2022-09-09T16:21:03.908+0000] {processor.py:153} INFO - Started process (PID=2886) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:21:03.909+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:21:03.909+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:21:03.909+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:21:06.962+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:21:08.128+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T16:21:08.129+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T16:21:08.129+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T16:21:08.129+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T16:21:08.129+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T16:21:08.129+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:21:08.129+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:21:08.129+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:21:08.129+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T16:21:08.130+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T16:21:08.130+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T16:21:08.130+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:21:08.130+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:21:08.130+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:21:08.130+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T16:21:08.130+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:21:08.130+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T16:21:08.130+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T16:21:08.133+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:21:08.131+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T16:21:08.133+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:21:08.689+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.785 seconds
[2022-09-09T16:21:39.216+0000] {processor.py:153} INFO - Started process (PID=3067) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:21:39.216+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:21:39.217+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:21:39.217+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:22:09.218+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:22:09.218+0000] {timeout.py:67} ERROR - Process timed out, PID: 3067
[2022-09-09T16:22:09.219+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:22:09.218+0000] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark-app.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#reducing-dag-complexity, PID: 3067
[2022-09-09T16:22:36.203+0000] {processor.py:153} INFO - Started process (PID=3149) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:22:37.147+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:22:37.148+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:22:37.148+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:22:42.096+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:22:44.331+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T16:22:44.331+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T16:22:44.331+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T16:22:44.331+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T16:22:44.331+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T16:22:44.331+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:22:44.331+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:22:44.332+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:22:44.332+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T16:22:44.332+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T16:22:44.332+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T16:22:44.332+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:22:44.332+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:22:44.332+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:22:44.332+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T16:22:44.332+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:22:44.332+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T16:22:44.332+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T16:22:44.334+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:22:44.332+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T16:22:44.335+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:22:44.403+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 8.204 seconds
[2022-09-09T16:23:14.730+0000] {processor.py:153} INFO - Started process (PID=3338) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:23:14.730+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:23:14.731+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:23:14.730+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:23:17.752+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:23:26.491+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T16:23:26.492+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T16:23:26.492+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T16:23:26.492+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T16:23:26.492+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T16:23:26.493+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:23:26.493+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:23:26.493+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:23:26.493+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T16:23:26.493+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T16:23:26.493+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T16:23:26.493+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:23:26.493+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:23:26.494+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:23:26.494+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T16:23:26.494+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:23:26.494+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T16:23:26.494+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T16:23:26.497+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:23:26.494+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T16:23:26.497+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:23:26.578+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 11.851 seconds
[2022-09-09T16:23:57.497+0000] {processor.py:153} INFO - Started process (PID=3550) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:23:57.521+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:23:57.523+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:23:57.523+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:24:00.269+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:24:01.435+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T16:24:01.435+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T16:24:01.443+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T16:24:01.443+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T16:24:01.443+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T16:24:01.443+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:24:01.443+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:24:01.443+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:24:01.443+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T16:24:01.444+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T16:24:01.444+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T16:24:01.444+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:24:01.444+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:24:01.444+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:24:01.444+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T16:24:01.444+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:24:01.444+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T16:24:01.444+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T16:24:01.446+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:24:01.444+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T16:24:01.446+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:24:01.526+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 4.032 seconds
[2022-09-09T16:24:31.744+0000] {processor.py:153} INFO - Started process (PID=3728) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:24:31.744+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:24:31.745+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:24:31.745+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:24:34.367+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:24:35.444+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T16:24:35.444+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
[2022-09-09T16:24:35.444+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
[2022-09-09T16:24:35.444+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
[2022-09-09T16:24:35.445+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
[2022-09-09T16:24:35.445+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:24:35.445+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:24:35.445+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:24:35.445+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
[2022-09-09T16:24:35.445+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
[2022-09-09T16:24:35.445+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
[2022-09-09T16:24:35.445+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:24:35.445+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
[2022-09-09T16:24:35.445+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:24:35.445+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
[2022-09-09T16:24:35.445+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
[2022-09-09T16:24:35.445+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
[2022-09-09T16:24:35.445+0000] {logging_mixin.py:115} WARNING - ValueError: Cell is empty
[2022-09-09T16:24:35.447+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:24:35.446+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 458, in dumps
    return cloudpickle.dumps(obj, pickle_protocol)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 102, in dumps
    cp.dump(obj)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 602, in dump
    return Pickler.dump(self, obj)
  File "/usr/local/lib/python3.7/pickle.py", line 437, in dump
    self.save(obj)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 784, in save_function
    *self._dynamic_function_reduce(obj), obj=obj
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/cloudpickle/cloudpickle_fast.py", line 721, in _save_reduce_pickle5
    dictitems=dictitems, obj=obj
  File "/usr/local/lib/python3.7/pickle.py", line 638, in save_reduce
    save(args)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 789, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/usr/local/lib/python3.7/pickle.py", line 774, in save_tuple
    save(element)
  File "/usr/local/lib/python3.7/pickle.py", line 504, in save
    f(self, obj) # Call unbound method with explicit self
  File "/home/airflow/.local/lib/python3.7/site-packages/dill/_dill.py", line 1146, in save_cell
    f = obj.cell_contents
ValueError: Cell is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 14, in <module>
    df = sqlContext.createDataFrame(data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 472, in createDataFrame
    data, schema, samplingRatio, verifySchema
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 895, in createDataFrame
    data, schema, samplingRatio, verifySchema  # type: ignore[arg-type]
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/session.py", line 938, in _create_dataframe
    jrdd = self._jvm.SerDeUtil.toJavaArray(rdd._to_java_object_rdd())
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3113, in _to_java_object_rdd
    return self.ctx._jvm.SerDeUtil.pythonToJava(rdd._jrdd, True)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3506, in _jrdd
    self.ctx, self.func, self._prev_jrdd_deserializer, self._jrdd_deserializer, profiler
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3362, in _wrap_function
    pickled_command, broadcast_vars, env, includes = _prepare_for_python_RDD(sc, command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/rdd.py", line 3345, in _prepare_for_python_RDD
    pickled_command = ser.dumps(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/serializers.py", line 468, in dumps
    raise pickle.PicklingError(msg)
_pickle.PicklingError: Could not serialize object: ValueError: Cell is empty
[2022-09-09T16:24:35.448+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:24:35.492+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 3.751 seconds
[2022-09-09T16:24:51.591+0000] {processor.py:153} INFO - Started process (PID=3883) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:24:51.592+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:24:51.593+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:24:51.593+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:24:54.549+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:24:54.649+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:24:55.350+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:24:55.343+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 18, in <module>
    df = sqlContext.read.csv('file:///opt/airflow/dags/spark_jobs/bronze/ips.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/readwriter.py", line 535, in csv
    return self._df(self._jreader.csv(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1322, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/utils.py", line 196, in deco
    raise converted from None
pyspark.sql.utils.AnalysisException: Path does not exist: file:/opt/airflow/dags/spark_jobs/bronze/ips.csv
[2022-09-09T16:24:55.354+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:24:55.447+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 3.858 seconds
[2022-09-09T16:25:26.212+0000] {processor.py:153} INFO - Started process (PID=4065) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:25:26.268+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:25:26.269+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:25:26.268+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:25:29.024+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:25:29.109+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:25:29.854+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:25:29.846+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 18, in <module>
    df = sqlContext.read.csv('file:///opt/airflow/dags/spark_jobs/bronze/ips.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/readwriter.py", line 535, in csv
    return self._df(self._jreader.csv(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1322, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/utils.py", line 196, in deco
    raise converted from None
pyspark.sql.utils.AnalysisException: Path does not exist: file:/opt/airflow/dags/spark_jobs/bronze/ips.csv
[2022-09-09T16:25:29.858+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:25:29.938+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 3.729 seconds
[2022-09-09T16:26:00.518+0000] {processor.py:153} INFO - Started process (PID=4244) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:26:00.534+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:26:00.534+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:26:00.534+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:26:03.541+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:26:03.637+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:26:04.377+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:26:04.370+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 18, in <module>
    df = sqlContext.read.csv('file:///opt/airflow/dags/spark_jobs/bronze/ips.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/readwriter.py", line 535, in csv
    return self._df(self._jreader.csv(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1322, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/utils.py", line 196, in deco
    raise converted from None
pyspark.sql.utils.AnalysisException: Path does not exist: file:/opt/airflow/dags/spark_jobs/bronze/ips.csv
[2022-09-09T16:26:04.380+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:26:04.465+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 3.949 seconds
[2022-09-09T16:26:10.492+0000] {processor.py:153} INFO - Started process (PID=4368) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:26:10.493+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:26:10.493+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:26:10.493+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:26:13.431+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:26:13.540+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:26:40.494+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:26:40.494+0000] {timeout.py:67} ERROR - Process timed out, PID: 4368
[2022-09-09T16:26:40.495+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:26:40.494+0000] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark-app.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#reducing-dag-complexity, PID: 4368
[2022-09-09T16:26:40.496+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:26:40.495+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-09-09T16:26:40.496+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:26:40.496+0000] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark-app.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#reducing-dag-complexity, PID: 4368

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-09-09T16:26:40.497+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:26:40.497+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-09-09T16:26:40.498+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:26:40.497+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 18, in <module>
    df = sqlContext.read.csv('file:///opt/airflow/dags/spark_jobs/dados/bronze/ips.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/readwriter.py", line 535, in csv
    return self._df(self._jreader.csv(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1322, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/utils.py", line 190, in deco
    return f(*a, **kw)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling o29.csv
[2022-09-09T16:26:40.498+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:26:43.188+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 32.699 seconds
[2022-09-09T16:27:30.737+0000] {processor.py:153} INFO - Started process (PID=4559) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:27:30.777+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:27:30.777+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:27:30.777+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:27:33.696+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:27:33.786+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:27:37.361+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:27:37.361+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:27:37.362+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:27:37.545+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.812 seconds
[2022-09-09T16:28:08.054+0000] {processor.py:153} INFO - Started process (PID=4772) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:28:08.109+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:28:08.110+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:28:08.110+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:28:11.005+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:28:13.312+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:28:17.061+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:28:17.062+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:28:17.062+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:28:17.073+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 9.022 seconds
[2022-09-09T16:28:47.351+0000] {processor.py:153} INFO - Started process (PID=4954) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:28:47.368+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:28:47.369+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:28:47.369+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:28:50.347+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:28:50.440+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:28:53.921+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:28:53.921+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:28:53.922+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:28:53.934+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.586 seconds
[2022-09-09T16:29:24.130+0000] {processor.py:153} INFO - Started process (PID=5345) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:29:24.142+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:29:24.143+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:29:24.143+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:29:27.228+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:29:27.318+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:29:30.671+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:29:30.671+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:29:30.671+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:29:30.683+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.555 seconds
[2022-09-09T16:30:01.820+0000] {processor.py:153} INFO - Started process (PID=5631) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:30:01.833+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:30:01.834+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:30:01.834+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:30:51.618+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:30:51.617+0000] {timeout.py:67} ERROR - Process timed out, PID: 5631
[2022-09-09T16:30:51.618+0000] {logging_mixin.py:115} WARNING - Exception ignored in: <function _releaseLock at 0x7fb1606c28c0>
[2022-09-09T16:30:51.618+0000] {logging_mixin.py:115} WARNING - Traceback (most recent call last):
[2022-09-09T16:30:51.618+0000] {logging_mixin.py:115} WARNING -   File "/usr/local/lib/python3.7/logging/__init__.py", line 221, in _releaseLock
[2022-09-09T16:30:51.619+0000] {logging_mixin.py:115} WARNING -     def _releaseLock():
[2022-09-09T16:30:51.619+0000] {logging_mixin.py:115} WARNING -   File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
[2022-09-09T16:30:51.619+0000] {logging_mixin.py:115} WARNING -     raise AirflowTaskTimeout(self.error_message)
[2022-09-09T16:30:51.619+0000] {logging_mixin.py:115} WARNING - airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark-app.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#reducing-dag-complexity, PID: 5631
[2022-09-09T16:30:55.375+0000] {processor.py:153} INFO - Started process (PID=5747) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:30:55.475+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:30:55.476+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:30:55.476+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:31:19.637+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:31:19.820+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:31:25.477+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:31:25.477+0000] {timeout.py:67} ERROR - Process timed out, PID: 5747
[2022-09-09T16:31:25.478+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:31:25.477+0000] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark-app.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#reducing-dag-complexity, PID: 5747
[2022-09-09T16:31:25.478+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:31:25.478+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-09-09T16:31:25.479+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:31:25.478+0000] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark-app.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#reducing-dag-complexity, PID: 5747

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-09-09T16:31:25.479+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:31:25.479+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-09-09T16:31:25.480+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:31:25.479+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 18, in <module>
    df = sqlContext.read.csv('file:///opt/airflow/dags/spark_jobs/dados/bronze/ips.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/readwriter.py", line 535, in csv
    return self._df(self._jreader.csv(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1322, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/utils.py", line 190, in deco
    return f(*a, **kw)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling o29.csv
[2022-09-09T16:31:25.480+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:31:25.656+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 30.284 seconds
[2022-09-09T16:31:56.114+0000] {processor.py:153} INFO - Started process (PID=6058) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:31:56.150+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:31:56.151+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:31:56.151+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:32:19.283+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:32:19.396+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:32:26.152+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:32:26.151+0000] {timeout.py:67} ERROR - Process timed out, PID: 6058
[2022-09-09T16:32:26.153+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:32:26.152+0000] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark-app.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#reducing-dag-complexity, PID: 6058
[2022-09-09T16:32:26.153+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:32:26.153+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-09-09T16:32:26.154+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:32:26.153+0000] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark-app.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#reducing-dag-complexity, PID: 6058

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-09-09T16:32:26.154+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:32:26.154+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-09-09T16:32:26.155+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:32:26.154+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 18, in <module>
    df = sqlContext.read.csv('file:///opt/airflow/dags/spark_jobs/dados/bronze/ips.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/readwriter.py", line 535, in csv
    return self._df(self._jreader.csv(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1322, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/utils.py", line 190, in deco
    return f(*a, **kw)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling o29.csv
[2022-09-09T16:32:26.156+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:32:26.654+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 30.542 seconds
[2022-09-09T16:32:57.239+0000] {processor.py:153} INFO - Started process (PID=6418) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:32:57.272+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:32:57.273+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:32:57.272+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:33:00.523+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:33:00.614+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:33:04.709+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:33:04.709+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:33:04.710+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:33:04.919+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 7.682 seconds
[2022-09-09T16:33:35.109+0000] {processor.py:153} INFO - Started process (PID=6753) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:33:35.146+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:33:35.146+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:33:35.146+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:33:38.204+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:33:38.304+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:33:42.172+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:33:42.173+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:33:42.173+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:33:42.185+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 7.078 seconds
[2022-09-09T16:34:12.623+0000] {processor.py:153} INFO - Started process (PID=7108) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:34:12.696+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:34:12.696+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:34:12.696+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:34:15.771+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:34:15.880+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:34:19.913+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:34:19.913+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:34:19.913+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:34:19.926+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 7.305 seconds
[2022-09-09T16:34:49.983+0000] {processor.py:153} INFO - Started process (PID=7456) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:34:50.036+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:34:50.037+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:34:50.037+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:34:52.875+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:34:52.959+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:34:56.430+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:34:56.430+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:34:56.430+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:34:56.441+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.460 seconds
[2022-09-09T16:35:27.077+0000] {processor.py:153} INFO - Started process (PID=7801) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:35:27.093+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:35:27.094+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:35:27.094+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:35:29.927+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:35:30.020+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:35:33.490+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:35:33.490+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:35:33.490+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:35:33.504+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.429 seconds
[2022-09-09T16:36:03.604+0000] {processor.py:153} INFO - Started process (PID=8165) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:36:03.614+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:36:03.614+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:36:03.614+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:36:06.428+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:36:06.523+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:36:10.021+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:36:10.021+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:36:10.021+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:36:10.033+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.432 seconds
[2022-09-09T16:36:40.448+0000] {processor.py:153} INFO - Started process (PID=8507) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:36:40.476+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:36:40.477+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:36:40.477+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:36:43.203+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:36:43.291+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:36:47.098+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:36:47.098+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:36:47.098+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:36:47.110+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.665 seconds
[2022-09-09T16:37:17.504+0000] {processor.py:153} INFO - Started process (PID=8846) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:37:17.533+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:37:17.534+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:37:17.534+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:37:20.564+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:37:20.654+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:37:24.293+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:37:24.293+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:37:24.293+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:37:24.355+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.854 seconds
[2022-09-09T16:37:54.767+0000] {processor.py:153} INFO - Started process (PID=9200) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:37:54.794+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:37:54.795+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:37:54.795+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:37:57.820+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:37:57.911+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:38:01.526+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:38:01.527+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:38:01.527+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:38:01.587+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.823 seconds
[2022-09-09T16:38:32.151+0000] {processor.py:153} INFO - Started process (PID=9550) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:38:32.152+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:38:32.152+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:38:32.152+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:38:34.993+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:38:35.102+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:38:38.511+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:38:38.511+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:38:38.511+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:38:38.525+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.377 seconds
[2022-09-09T16:39:09.088+0000] {processor.py:153} INFO - Started process (PID=9909) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:39:09.106+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:39:09.107+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:39:09.107+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:39:11.891+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:39:11.975+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:39:15.369+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:39:15.369+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:39:15.369+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:39:15.385+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.299 seconds
[2022-09-09T16:39:45.824+0000] {processor.py:153} INFO - Started process (PID=10248) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:39:45.864+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:39:45.864+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:39:45.864+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:39:48.560+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:39:48.659+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:39:52.279+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:39:52.279+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:39:52.279+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:39:52.290+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.469 seconds
[2022-09-09T16:40:22.970+0000] {processor.py:153} INFO - Started process (PID=10597) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:40:22.971+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:40:22.971+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:40:22.971+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:40:26.008+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:40:26.093+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:40:29.548+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:40:29.548+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:40:29.549+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:40:29.563+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.596 seconds
[2022-09-09T16:40:59.793+0000] {processor.py:153} INFO - Started process (PID=10944) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:40:59.848+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:40:59.848+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:40:59.848+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:41:02.830+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:41:02.917+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:41:06.601+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:41:06.601+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:41:06.601+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:41:06.613+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.823 seconds
[2022-09-09T16:41:36.830+0000] {processor.py:153} INFO - Started process (PID=11298) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:41:36.846+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:41:36.846+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:41:36.846+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:41:39.704+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:41:39.794+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:41:43.573+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:41:43.573+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:41:43.573+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:41:43.587+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.760 seconds
[2022-09-09T16:42:13.688+0000] {processor.py:153} INFO - Started process (PID=11670) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:42:13.703+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:42:13.704+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:42:13.704+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:42:16.515+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:42:16.624+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:42:20.123+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:42:20.123+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:42:20.123+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:42:20.136+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.450 seconds
[2022-09-09T16:42:50.944+0000] {processor.py:153} INFO - Started process (PID=12017) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:42:50.961+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:42:50.961+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:42:50.961+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:42:53.823+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:42:53.915+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:42:57.759+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:42:57.759+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:42:57.759+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:42:57.771+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.830 seconds
[2022-09-09T16:44:03.907+0000] {processor.py:153} INFO - Started process (PID=12380) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:44:03.955+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:44:03.956+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:44:03.956+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:44:07.296+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:44:08.685+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:44:33.957+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:44:33.957+0000] {timeout.py:67} ERROR - Process timed out, PID: 12380
[2022-09-09T16:44:33.963+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:44:33.957+0000] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark-app.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#reducing-dag-complexity, PID: 12380
[2022-09-09T16:44:33.964+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:44:33.964+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-09-09T16:44:33.969+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:44:33.964+0000] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark-app.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#reducing-dag-complexity, PID: 12380

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-09-09T16:44:33.970+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:44:33.970+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-09-09T16:44:33.971+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:44:33.970+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 18, in <module>
    df = sqlContext.read.csv('file:///opt/airflow/dags/spark_jobs/dados/bronze/ips.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py", line 649, in read
    return DataFrameReader(self.sparkSession)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/readwriter.py", line 66, in __init__
    self._jreader = spark._jsparkSession.read()
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1322, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/utils.py", line 190, in deco
    return f(*a, **kw)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling o27.read
[2022-09-09T16:44:33.971+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:45:23.343+0000] {processor.py:153} INFO - Started process (PID=12850) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:45:23.391+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:45:23.391+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:45:23.391+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:45:26.254+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:45:26.340+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:45:29.685+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:45:29.685+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:45:29.685+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:45:29.731+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.392 seconds
[2022-09-09T16:46:30.102+0000] {processor.py:153} INFO - Started process (PID=13391) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:46:30.246+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:46:30.247+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:46:30.247+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:46:33.437+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:46:33.528+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:46:37.088+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:46:37.089+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:46:37.089+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:46:37.101+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 7.003 seconds
[2022-09-09T16:47:22.666+0000] {processor.py:153} INFO - Started process (PID=13924) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:47:22.803+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:47:22.804+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:47:22.804+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:47:25.760+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:47:25.858+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:47:29.266+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:47:29.266+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:47:29.267+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:47:29.279+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.615 seconds
[2022-09-09T16:48:22.382+0000] {processor.py:153} INFO - Started process (PID=14478) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:48:22.402+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:48:22.403+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:48:22.402+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:48:25.722+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:48:25.813+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:48:29.662+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:48:29.662+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:48:29.662+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:48:29.677+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 7.298 seconds
[2022-09-09T16:49:02.660+0000] {processor.py:153} INFO - Started process (PID=14983) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:49:02.675+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:49:02.676+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:49:02.676+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:49:07.591+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:49:07.685+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:49:14.495+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:49:14.496+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:49:14.496+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:49:14.506+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 11.849 seconds
[2022-09-09T16:49:44.782+0000] {processor.py:153} INFO - Started process (PID=15500) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:49:44.932+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:49:44.933+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:49:44.933+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:49:47.917+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:49:48.012+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:49:51.682+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:49:51.683+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:49:51.683+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:49:51.697+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.918 seconds
[2022-09-09T16:50:21.791+0000] {processor.py:153} INFO - Started process (PID=15997) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:50:21.823+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:50:21.823+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:50:21.823+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:50:24.663+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:50:24.749+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:50:28.290+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:50:28.290+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:50:28.291+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:50:28.304+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.515 seconds
[2022-09-09T16:50:58.682+0000] {processor.py:153} INFO - Started process (PID=16345) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:50:58.822+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:50:58.822+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:50:58.822+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:51:01.713+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:51:01.809+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:51:05.856+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:51:05.857+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:51:05.931+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:51:05.944+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 7.265 seconds
[2022-09-09T16:51:36.041+0000] {processor.py:153} INFO - Started process (PID=16857) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:51:36.149+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:51:36.149+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:51:36.149+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:51:39.210+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:51:39.302+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:51:43.125+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:51:43.125+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:51:43.126+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:51:43.155+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 7.117 seconds
[2022-09-09T16:52:13.721+0000] {processor.py:153} INFO - Started process (PID=17361) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:52:13.730+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:52:13.730+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:52:13.730+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:52:16.808+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:52:16.906+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:52:20.713+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:52:20.713+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:52:20.713+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:52:20.728+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 7.009 seconds
[2022-09-09T16:52:53.795+0000] {processor.py:153} INFO - Started process (PID=17865) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:52:53.797+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:52:53.798+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:52:53.798+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:52:58.526+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:52:58.624+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:53:02.235+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:53:02.235+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:53:02.235+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:53:02.248+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 8.457 seconds
[2022-09-09T16:53:53.272+0000] {processor.py:153} INFO - Started process (PID=18320) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:53:53.317+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:53:53.317+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:53:53.317+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:53:56.484+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:53:56.594+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:54:01.234+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:54:01.234+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:54:01.235+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:54:01.250+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 7.980 seconds
[2022-09-09T16:54:31.523+0000] {processor.py:153} INFO - Started process (PID=18708) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:54:31.549+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:54:31.550+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:54:31.549+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:54:34.274+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:54:34.364+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:54:38.205+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:54:38.205+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:54:38.206+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:54:38.216+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.696 seconds
[2022-09-09T16:55:08.249+0000] {processor.py:153} INFO - Started process (PID=19209) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:55:08.264+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:55:08.265+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:55:08.265+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:55:11.016+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:55:11.101+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:55:14.622+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:55:14.622+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:55:14.622+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:55:14.635+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.389 seconds
[2022-09-09T16:55:45.027+0000] {processor.py:153} INFO - Started process (PID=19668) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:55:45.088+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:55:45.089+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:55:45.089+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:55:48.223+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:55:48.322+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:55:51.984+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:55:51.984+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:55:51.984+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:55:51.997+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.973 seconds
[2022-09-09T16:56:22.208+0000] {processor.py:153} INFO - Started process (PID=20074) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:56:22.222+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:56:22.223+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:56:22.223+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:56:25.400+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:56:25.522+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:56:29.611+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:56:29.611+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:56:29.611+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:56:29.625+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 7.420 seconds
[2022-09-09T16:57:00.289+0000] {processor.py:153} INFO - Started process (PID=20601) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:57:00.290+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:57:00.290+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:57:00.290+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:57:03.277+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:57:03.375+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:57:06.826+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:57:06.826+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:57:06.826+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:57:06.839+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.552 seconds
[2022-09-09T16:57:42.343+0000] {processor.py:153} INFO - Started process (PID=21130) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:57:42.344+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:57:42.344+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:57:42.344+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:57:45.233+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:57:45.336+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:57:57.791+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T16:57:57.791+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T16:57:57.792+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:57:59.411+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 17.071 seconds
[2022-09-09T16:59:06.009+0000] {processor.py:153} INFO - Started process (PID=21673) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T16:59:06.010+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T16:59:06.011+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:59:06.011+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T16:59:09.542+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T16:59:09.654+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T16:59:50.506+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:59:50.506+0000] {timeout.py:67} ERROR - Process timed out, PID: 21673
[2022-09-09T16:59:50.508+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:59:50.507+0000] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark-app.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#reducing-dag-complexity, PID: 21673
[2022-09-09T16:59:50.523+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:59:50.523+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-09-09T16:59:50.524+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:59:50.523+0000] {java_gateway.py:1056} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.7/socket.py", line 589, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark-app.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#reducing-dag-complexity, PID: 21673

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/clientserver.py", line 540, in send_command
    "Error while sending or receiving", e, proto.ERROR_ON_RECEIVE)
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-09-09T16:59:50.524+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:59:50.524+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2022-09-09T16:59:50.524+0000] {logging_mixin.py:115} INFO - [2022-09-09T16:59:50.524+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 18, in <module>
    df = sqlContext.read.csv('file:///opt/airflow/dags/spark_jobs/dados/bronze/ips.csv')
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/readwriter.py", line 535, in csv
    return self._df(self._jreader.csv(self._spark._sc._jvm.PythonUtils.toSeq(path)))
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/java_gateway.py", line 1322, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/utils.py", line 190, in deco
    return f(*a, **kw)
  File "/home/airflow/.local/lib/python3.7/site-packages/py4j/protocol.py", line 336, in get_return_value
    format(target_id, ".", name))
py4j.protocol.Py4JError: An error occurred while calling o29.csv
[2022-09-09T16:59:50.525+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T16:59:52.357+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 46.351 seconds
[2022-09-09T17:00:22.422+0000] {processor.py:153} INFO - Started process (PID=22485) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T17:00:22.422+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T17:00:22.422+0000] {logging_mixin.py:115} INFO - [2022-09-09T17:00:22.422+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T17:00:25.178+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T17:00:25.262+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T17:00:29.123+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T17:00:29.123+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T17:00:29.123+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T17:00:29.239+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.820 seconds
[2022-09-09T17:00:59.270+0000] {processor.py:153} INFO - Started process (PID=22994) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T17:00:59.271+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T17:00:59.271+0000] {logging_mixin.py:115} INFO - [2022-09-09T17:00:59.271+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T17:01:02.188+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T17:01:02.294+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T17:01:09.949+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T17:01:09.950+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T17:01:09.950+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T17:01:09.962+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 10.695 seconds
[2022-09-09T17:01:53.463+0000] {processor.py:153} INFO - Started process (PID=23546) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T17:01:53.496+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T17:01:53.497+0000] {logging_mixin.py:115} INFO - [2022-09-09T17:01:53.497+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T17:01:56.746+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T17:01:56.835+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T17:02:00.972+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T17:02:00.973+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T17:02:00.973+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T17:02:00.988+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 7.529 seconds
[2022-09-09T17:02:38.079+0000] {processor.py:153} INFO - Started process (PID=24364) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T17:02:38.088+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T17:02:38.088+0000] {logging_mixin.py:115} INFO - [2022-09-09T17:02:38.088+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T17:02:41.031+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T17:02:41.118+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T17:02:44.498+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T17:02:44.499+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T17:02:44.499+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T17:02:44.512+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.436 seconds
[2022-09-09T17:03:15.582+0000] {processor.py:153} INFO - Started process (PID=25040) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T17:03:15.582+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T17:03:15.583+0000] {logging_mixin.py:115} INFO - [2022-09-09T17:03:15.583+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T17:03:18.431+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T17:03:18.521+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T17:03:21.877+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T17:03:21.878+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T17:03:21.878+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T17:03:21.889+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.310 seconds
[2022-09-09T17:03:55.916+0000] {processor.py:153} INFO - Started process (PID=25732) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T17:03:55.917+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T17:03:55.917+0000] {logging_mixin.py:115} INFO - [2022-09-09T17:03:55.917+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T17:03:58.728+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T17:03:58.826+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T17:04:02.352+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T17:04:02.352+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T17:04:02.352+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T17:04:02.415+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.502 seconds
[2022-09-09T17:04:33.822+0000] {processor.py:153} INFO - Started process (PID=26249) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T17:04:33.823+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T17:04:33.823+0000] {logging_mixin.py:115} INFO - [2022-09-09T17:04:33.823+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T17:04:36.625+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T17:04:36.718+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T17:04:40.505+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T17:04:40.506+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T17:04:40.506+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T17:04:40.521+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.702 seconds
[2022-09-09T17:05:12.171+0000] {processor.py:153} INFO - Started process (PID=26933) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T17:05:12.193+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T17:05:12.193+0000] {logging_mixin.py:115} INFO - [2022-09-09T17:05:12.193+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T17:05:14.946+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T17:05:15.040+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T17:05:18.303+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T17:05:18.303+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T17:05:18.303+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T17:05:18.314+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.146 seconds
[2022-09-09T17:05:50.396+0000] {processor.py:153} INFO - Started process (PID=27617) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T17:05:50.416+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T17:05:50.417+0000] {logging_mixin.py:115} INFO - [2022-09-09T17:05:50.417+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T17:05:53.296+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T17:05:53.390+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T17:05:56.825+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T17:05:56.825+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T17:05:56.825+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T17:05:56.838+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.445 seconds
[2022-09-09T17:06:29.468+0000] {processor.py:153} INFO - Started process (PID=28289) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T17:06:29.474+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T17:06:29.474+0000] {logging_mixin.py:115} INFO - [2022-09-09T17:06:29.474+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T17:06:32.353+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T17:06:32.442+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T17:06:36.041+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T17:06:36.041+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T17:06:36.041+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T17:06:36.054+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.589 seconds
[2022-09-09T17:07:07.043+0000] {processor.py:153} INFO - Started process (PID=28815) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T17:07:07.069+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T17:07:07.069+0000] {logging_mixin.py:115} INFO - [2022-09-09T17:07:07.069+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T17:07:09.970+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T17:07:10.062+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T17:07:14.042+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T17:07:14.042+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T17:07:14.042+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T17:07:14.059+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 7.018 seconds
[2022-09-09T17:07:45.493+0000] {processor.py:153} INFO - Started process (PID=29494) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T17:07:45.500+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T17:07:45.500+0000] {logging_mixin.py:115} INFO - [2022-09-09T17:07:45.500+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T17:07:48.340+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T17:07:48.433+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T17:07:52.012+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T17:07:52.012+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T17:07:52.012+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T17:07:52.025+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.535 seconds
[2022-09-09T17:08:23.634+0000] {processor.py:153} INFO - Started process (PID=30172) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T17:08:23.646+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T17:08:23.646+0000] {logging_mixin.py:115} INFO - [2022-09-09T17:08:23.646+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T17:08:26.872+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T17:08:26.960+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T17:08:30.721+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T17:08:30.721+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T17:08:30.722+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T17:08:30.735+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 7.103 seconds
[2022-09-09T17:09:10.465+0000] {processor.py:153} INFO - Started process (PID=30879) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T17:09:10.490+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T17:09:10.491+0000] {logging_mixin.py:115} INFO - [2022-09-09T17:09:10.491+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T17:09:13.322+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T17:09:13.428+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T17:09:16.750+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T17:09:16.750+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T17:09:16.750+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T17:09:16.763+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.301 seconds
[2022-09-09T17:09:47.026+0000] {processor.py:153} INFO - Started process (PID=31744) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T17:09:47.027+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T17:09:47.028+0000] {logging_mixin.py:115} INFO - [2022-09-09T17:09:47.028+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T17:09:50.019+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T17:09:50.126+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T17:09:53.597+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T17:09:53.597+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T17:09:53.598+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T17:09:53.610+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.587 seconds
[2022-09-09T17:12:45.326+0000] {processor.py:153} INFO - Started process (PID=637) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T17:13:09.680+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T17:13:09.719+0000] {logging_mixin.py:115} INFO - [2022-09-09T17:13:09.719+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T17:13:19.818+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T17:13:19.905+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T17:13:23.698+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T17:13:23.698+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T17:13:23.698+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T17:13:23.712+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 38.393 seconds
[2022-09-09T17:14:27.251+0000] {processor.py:153} INFO - Started process (PID=1813) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T17:14:27.253+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T17:14:27.254+0000] {logging_mixin.py:115} INFO - [2022-09-09T17:14:27.253+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T17:14:30.180+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T17:14:30.276+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T17:14:33.780+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T17:14:33.781+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T17:14:33.781+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T17:14:33.793+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.545 seconds
[2022-09-09T17:15:23.005+0000] {processor.py:153} INFO - Started process (PID=2637) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T17:15:23.006+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T17:15:23.007+0000] {logging_mixin.py:115} INFO - [2022-09-09T17:15:23.007+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T17:15:26.569+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T17:15:26.676+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T17:15:30.221+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T17:15:30.221+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T17:15:30.221+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T17:15:30.233+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 7.231 seconds
[2022-09-09T17:16:10.339+0000] {processor.py:153} INFO - Started process (PID=3495) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T17:16:10.407+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T17:16:10.408+0000] {logging_mixin.py:115} INFO - [2022-09-09T17:16:10.408+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T17:16:13.195+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T17:16:13.282+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T17:16:16.854+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T17:16:16.854+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T17:16:16.854+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T17:16:16.867+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.531 seconds
[2022-09-09T17:16:57.299+0000] {processor.py:153} INFO - Started process (PID=4393) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T17:16:57.398+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T17:16:57.398+0000] {logging_mixin.py:115} INFO - [2022-09-09T17:16:57.398+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T17:17:00.340+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T17:17:00.430+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T17:17:03.836+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T17:17:03.836+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T17:17:03.836+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T17:17:03.849+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.553 seconds
[2022-09-09T17:18:37.723+0000] {processor.py:153} INFO - Started process (PID=5073) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T17:18:37.762+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T17:18:37.763+0000] {logging_mixin.py:115} INFO - [2022-09-09T17:18:37.763+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T17:19:07.764+0000] {logging_mixin.py:115} INFO - [2022-09-09T17:19:07.764+0000] {timeout.py:67} ERROR - Process timed out, PID: 5073
[2022-09-09T17:19:07.766+0000] {logging_mixin.py:115} INFO - [2022-09-09T17:19:07.765+0000] {dagbag.py:321} ERROR - Failed to import: /opt/airflow/dags/spark-app.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 318, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark-app.py", line 5, in <module>
    sc = SparkContext("local", "First App")
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 195, in __init__
    SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/context.py", line 417, in _ensure_initialized
    SparkContext._gateway = gateway or launch_gateway(conf)
  File "/home/airflow/.local/lib/python3.7/site-packages/pyspark/java_gateway.py", line 103, in launch_gateway
    time.sleep(0.1)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/timeout.py", line 68, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark-app.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.3.4/best-practices.html#reducing-dag-complexity, PID: 5073
[2022-09-09T17:19:07.766+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T17:20:56.593+0000] {processor.py:153} INFO - Started process (PID=5929) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T17:20:56.734+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T17:20:56.734+0000] {logging_mixin.py:115} INFO - [2022-09-09T17:20:56.734+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T17:20:59.543+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T17:20:59.633+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T17:21:02.973+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T17:21:02.973+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T17:21:02.974+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T17:21:03.511+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.920 seconds
[2022-09-09T17:21:38.301+0000] {processor.py:153} INFO - Started process (PID=6793) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T17:21:38.508+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T17:21:38.509+0000] {logging_mixin.py:115} INFO - [2022-09-09T17:21:38.508+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T17:21:41.391+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T17:21:41.483+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T17:21:45.085+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T17:21:45.085+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T17:21:45.086+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T17:21:45.098+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 6.799 seconds
[2022-09-09T17:22:19.879+0000] {processor.py:153} INFO - Started process (PID=7492) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T17:22:20.007+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T17:22:20.007+0000] {logging_mixin.py:115} INFO - [2022-09-09T17:22:20.007+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T17:22:23.408+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T17:22:23.525+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T17:22:27.654+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T17:22:27.654+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T17:22:27.654+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T17:22:27.668+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 7.792 seconds
[2022-09-09T17:25:58.245+0000] {processor.py:153} INFO - Started process (PID=9063) to work on /opt/airflow/dags/spark-app.py
[2022-09-09T17:25:58.592+0000] {processor.py:640} INFO - Processing file /opt/airflow/dags/spark-app.py for tasks to queue
[2022-09-09T17:25:58.593+0000] {logging_mixin.py:115} INFO - [2022-09-09T17:25:58.593+0000] {dagbag.py:508} INFO - Filling up the DagBag from /opt/airflow/dags/spark-app.py
[2022-09-09T17:26:01.651+0000] {logging_mixin.py:115} WARNING - /home/airflow/.local/lib/python3.7/site-packages/pyspark/sql/context.py:114 FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.
[2022-09-09T17:26:01.781+0000] {logging_mixin.py:115} INFO - parte 1
[2022-09-09T17:26:05.255+0000] {logging_mixin.py:115} INFO - root
 |-- _c0: string (nullable = true)
 |-- _c1: string (nullable = true)
 |-- _c2: string (nullable = true)
[2022-09-09T17:26:05.255+0000] {logging_mixin.py:115} INFO - parte 2
[2022-09-09T17:26:05.255+0000] {processor.py:652} WARNING - No viable dags retrieved from /opt/airflow/dags/spark-app.py
[2022-09-09T17:26:05.268+0000] {processor.py:161} INFO - Processing /opt/airflow/dags/spark-app.py took 7.027 seconds
